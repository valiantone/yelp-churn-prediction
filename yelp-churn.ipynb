{
 "metadata": {
  "name": "",
  "signature": "sha256:7316ef93acbf2d61b4f7df83ed91478652026dac5b7146692bc19bfe182f5320"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''Code Dependencies - scikit-learn, numpy, scipy, gensim, textblob, nltk'''\n",
      "#Reading data from json files\n",
      "#Step 1: Find stats for user_json\n",
      "from collections import OrderedDict\n",
      "import json\n",
      "\n",
      "users = {}\n",
      "cnt = 0\n",
      "f = open(\"yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_user.json\",'r')\n",
      "for u in f.read().splitlines():\n",
      "    j = json.loads(u)\n",
      "    if int(j[\"yelping_since\"].split(\"-\")[0])>2012:\n",
      "        users[j[\"user_id\"]] = {\"posts\":j[\"review_count\"],\"since\":j[\"yelping_since\"],\"reviews\":[]}\n",
      "        cnt+=j[\"review_count\"]\n",
      "f.close()\n",
      "\n",
      "#Merge json sets for review and users\n",
      "cnt2=0\n",
      "reviews = {}\n",
      "with open(\"yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_review.json\") as lines:\n",
      "    for u in lines:\n",
      "        j = json.loads(u)\n",
      "        if j[\"user_id\"] in users:\n",
      "            cnt2+=1\n",
      "            reviews[j[\"review_id\"]] = {\"funny\":j[\"votes\"][\"funny\"],\"useful\":j[\"votes\"][\"useful\"],\"cool\":j[\"votes\"][\"cool\"],\"user\":j[\"user_id\"],\"date\":j[\"date\"],\"text\":j[\"text\"],\"stars\":j[\"stars\"]}\n",
      "            users[j[\"user_id\"]][\"reviews\"].append(j[\"review_id\"])\n",
      "#print cnt2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "funny = []\n",
      "cool = []\n",
      "useful = []\n",
      "for u in users:\n",
      "    for r in users[u][\"reviews\"]:\n",
      "        if reviews[r][\"funny\"]>0:\n",
      "            funny += reviews[r][\"text\"].split(\".\")\n",
      "        if reviews[r][\"cool\"]>0:\n",
      "            cool += reviews[r][\"text\"].split(\".\")\n",
      "        if reviews[r][\"useful\"]>0:\n",
      "            useful += reviews[r][\"text\"].split(\".\")\n",
      "\n",
      "#stoplist = set('for a of the and to in are there their is'.split())\n",
      "textsf = [[word for word in document.lower().split()] for document in funny]\n",
      "textsc = [[word for word in document.lower().split()] for document in cool]\n",
      "textsu = [[word for word in document.lower().split()] for document in useful]\n",
      "#all_tokens = sum(texts, [])\n",
      "#tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
      "#texts = [[word for word in text if word not in tokens_once] for text in texts]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import corpora, models, similarities\n",
      "\n",
      "dictionary = corpora.Dictionary(textsf)\n",
      "corpus = [dictionary.doc2bow(text) for text in textsf]\n",
      "lda1 = models.ldamodel.LdaModel(corpus, id2word = dictionary, num_topics=20)\n",
      "X = []\n",
      "for i in range(20):\n",
      "     X.append((i,sum([top[0] for top in lda1.show_topic(i,20)])))\n",
      "X = sorted(X, key = lambda tup:tup[1], reverse = True)\n",
      "F = [X[i][0] for i in range(20)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = corpora.Dictionary(textsc)\n",
      "corpus = [dictionary.doc2bow(text) for text in textsc]\n",
      "lda2 = models.ldamodel.LdaModel(corpus, id2word = dictionary, num_topics=20)\n",
      "X = []\n",
      "for i in range(20):\n",
      "     X.append((i,sum([top[0] for top in lda2.show_topic(i,20)])))\n",
      "X = sorted(X, key = lambda tup:tup[1], reverse = True)\n",
      "C = [X[i][0] for i in range(20)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = corpora.Dictionary(textsu)\n",
      "corpus = [dictionary.doc2bow(text) for text in textsu]\n",
      "lda3 = models.ldamodel.LdaModel(corpus, id2word = dictionary, num_topics=20)\n",
      "X = []\n",
      "for i in range(20):\n",
      "     X.append((i,sum([top[0] for top in lda3.show_topic(i,20)])))\n",
      "X = sorted(X, key = lambda tup:tup[1], reverse = True)\n",
      "U = [X[i][0] for i in range(20)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "MemoryError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-39-33d128135f01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextsu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtextsu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlda3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\gensim\\models\\ldamodel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;31m# Initialize the variational distribution q(beta|lambda)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLdaState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m100.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\gensim\\models\\ldamodel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, eta, shape)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mMemoryError\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.svm import SVR, LinearSVC\n",
      "from textblob import TextBlob\n",
      "\n",
      "from sklearn.metrics import mean_squared_error, r2_score\n",
      "\n",
      "features = OrderedDict()\n",
      "for u in users:\n",
      "    if int(users[u][\"since\"].split(\"-\")[0])==2014:\n",
      "        users[u][\"membership\"] = 8 - int(users[u][\"since\"].split(\"-\")[1])\n",
      "    else:\n",
      "        users[u][\"membership\"] = 8 - int(users[u][\"since\"].split(\"-\")[1]) + 12\n",
      "    if len(users[u][\"reviews\"])>=5:\n",
      "        users[u][\"reviews\"] = sorted(users[u][\"reviews\"],key = lambda t:reviews[t][\"date\"])[:5]\n",
      "        features[u] = {\"posts\":users[u][\"posts\"],\"membership\":users[u][\"membership\"], \"funny\":sum(reviews[i][\"funny\"] for i in users[u][\"reviews\"]),\"cool\":sum(reviews[i][\"cool\"] for i in users[u][\"reviews\"]),\"useful\":sum(reviews[i][\"useful\"] for i in users[u][\"reviews\"])}\n",
      "        dumpf = []\n",
      "        dumpc = []\n",
      "        dumpu = []\n",
      "        sent = 0\n",
      "        length = 0\n",
      "        stars = 0\n",
      "        for r in users[u][\"reviews\"]:\n",
      "            stars += reviews[r][\"stars\"]\n",
      "            lines = reviews[r][\"text\"].split(\".\")\n",
      "            for line in lines:\n",
      "                t = TextBlob(line)\n",
      "                sent += t.sentiment.polarity\n",
      "                length += 1\n",
      "        \n",
      "            if reviews[r][\"funny\"]>0:\n",
      "                dumpf += reviews[r][\"text\"].split(\".\")\n",
      "            if reviews[r][\"cool\"]>0:\n",
      "                dumpc += reviews[r][\"text\"].split(\".\")\n",
      "            if reviews[r][\"useful\"]>0:\n",
      "                dumpu += reviews[r][\"text\"].split(\".\")\n",
      "        \n",
      "        \n",
      "        features[u][\"sent\"] = float(sent)/length\n",
      "        features[u][\"stars\"] = float(stars)/5\n",
      "        features[u][\"size\"] = float(length)/5\n",
      "        \n",
      "        texts = [[word for word in document.lower().split()] for document in dumpf]\n",
      "        dictionary = corpora.Dictionary(texts)\n",
      "        cc = [dictionary.doc2bow(text) for text in texts]\n",
      "        temp = {i:0 for i in range(20)}\n",
      "        for c in cc:\n",
      "            for tup in lda1[c]:\n",
      "                temp[tup[0]] += tup[1]\n",
      "        temp = sorted(temp.items(), key = lambda tup:tup[1], reverse = True)\n",
      "        T = [temp[i][0] for i in range(10)]\n",
      "        features[u][\"funjacc\"] = float(len(set(T).intersection(set(F))))/len(set(T).union(set(F)))\n",
      "        \n",
      "        texts = [[word for word in document.lower().split()] for document in dumpc]\n",
      "        dictionary = corpora.Dictionary(texts)\n",
      "        cc = [dictionary.doc2bow(text) for text in texts]\n",
      "        temp = {i:0 for i in range(20)}\n",
      "        for c in cc:\n",
      "            for tup in lda2[c]:\n",
      "                temp[tup[0]] += tup[1]\n",
      "        temp = sorted(temp.items(), key = lambda tup:tup[1], reverse = True)\n",
      "        T = [temp[i][0] for i in range(10)]    \n",
      "        features[u][\"cooljacc\"] = float(len(set(T).intersection(set(C))))/len(set(T).union(set(C)))\n",
      "        \n",
      "        texts = [[word for word in document.lower().split()] for document in dumpu]\n",
      "        dictionary = corpora.Dictionary(texts)\n",
      "        cc = [dictionary.doc2bow(text) for text in texts]\n",
      "        temp = {i:0 for i in range(20)}\n",
      "        for c in cc:\n",
      "            for tup in lda1[c]:\n",
      "                temp[tup[0]] += tup[1]\n",
      "        temp = sorted(temp.items(), key = lambda tup:tup[1], reverse = True)\n",
      "        T = [temp[i][0] for i in range(10)]\n",
      "        features[u][\"usejacc\"] = float(len(set(T).intersection(set(U))))/len(set(T).union(set(U)))        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = []\n",
      "train = []\n",
      "labelsR = []\n",
      "labelsT = []\n",
      "for f in features:\n",
      "    if len(labelsT)<=0.25*len(features):\n",
      "        test.append([features[f][\"funny\"],features[f][\"cool\"],features[f][\"useful\"],features[f][\"sent\"]])\n",
      "        labelsT.append(float(features[f][\"posts\"])/features[f][\"membership\"])\n",
      "    else:\n",
      "        train.append([features[f][\"funny\"],features[f][\"cool\"],features[f][\"useful\"],features[f][\"sent\"]])\n",
      "        labelsR.append(float(features[f][\"posts\"])/features[f][\"membership\"])\n",
      "#print len(labelsR)+len(labelsT), len(features)\n",
      "\n",
      "train = np.array(train)\n",
      "\n",
      "clf = LogisticRegression()\n",
      "clf.fit(train,labelsR)\n",
      "\n",
      "test = np.array(test)\n",
      "pred = clf.predict(test)\n",
      "\n",
      "#Computing interaction-based accuracy of predictor - evaluation\n",
      "#pred = [2.5]*len(pred)\n",
      "prc = [0,0,0]\n",
      "fn = [sum(i<1 for i in labelsT),sum(i>=1 and i<3 for i in labelsT),sum(i<=3 for i in labelsT)]\n",
      "for i in range(len(pred)):\n",
      "    if pred[i]<1 and labelsT[i]<1:\n",
      "        prc[0] += 1\n",
      "    elif pred[i]<2.5 and labelsT[i]<2.5:\n",
      "        prc[1] += 1\n",
      "    elif pred[i]>=2.5 and labelsT[i]>=2.5:\n",
      "        prc[2] += 1\n",
      "\n",
      "P = float(sum(prc))/len(pred)\n",
      "R = float(sum(prc))/sum(fn)\n",
      "\n",
      "print \"Precision: %f Recall: %f F-Score:%f Mean-Squared Error:%f R2:%f\" %(P,R,(2*P*R)/(P+R),mean_squared_error(labelsT,pred),r2_score(labelsT,pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Precision: 0.780856 Recall: 0.475278 F-Score:0.590898 Mean-Squared Error:13.530620 R2:-0.138454\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Logistic Regression\n",
      "B. Precision: 0.219773 Recall: 0.133768 F-Score:0.166309 Mean-Squared Error:11.976797 R2:-0.007716\n",
      "1. Precision: 0.779597 Recall: 0.474511 F-Score:0.589945 Mean-Squared Error:13.322416 R2:-0.120936\n",
      "2. Precision: 0.780856 Recall: 0.475278 F-Score:0.590898 Mean-Squared Error:13.529651 R2:-0.138372\n",
      "3. Precision: 0.780856 Recall: 0.475278 F-Score:0.590898 Mean-Squared Error:13.530620 R2:-0.138454\n",
      "4. Precision: 0.781486 Recall: 0.475661 F-Score:0.591375 Mean-Squared Error:13.528693 R2:-0.138291\n",
      "\n",
      "Gaussian NB\n",
      "B. Precision: 0.219773 Recall: 0.133768 F-Score:0.166309 Mean-Squared Error:11.976797 R2:-0.007716\n",
      "1. Precision: 0.461587 Recall: 0.280951 F-Score:0.349297 Mean-Squared Error:67.262571 R2:-4.659409\n",
      "2. Precision: 0.537154 Recall: 0.326945 F-Score:0.406481 Mean-Squared Error:25.613941 R2:-1.155133\n",
      "3. Precision: 0.465365 Recall: 0.283250 F-Score:0.352156 Mean-Squared Error:70.989265 R2:-4.972970\n",
      "4. Precision: 0.496222 Recall: 0.302031 F-Score:0.375506 Mean-Squared Error:73.413372 R2:-5.176932\n",
      "\n",
      "LinearSVC\n",
      "B. Precision: 0.219773 Recall: 0.133768 F-Score:0.166309 Mean-Squared Error:11.976797 R2:-0.007716\n",
      "1. Precision: 0.221033 Recall: 0.134534 F-Score:0.167262 Mean-Squared Error:15.579185 R2:-0.310818\n",
      "2. Precision: 0.761335 Recall: 0.463396 F-Score:0.576126 Mean-Squared Error:15.618086 R2:-0.314091\n",
      "3. Precision: 0.770151 Recall: 0.468762 F-Score:0.582797 Mean-Squared Error:13.779049 R2:-0.159356\n",
      "4. Precision: 0.711587 Recall: 0.433116 F-Score:0.538480 Mean-Squared Error:36.980011 R2:-2.111463\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print F\n",
      "print [i[1] for i in lda1.show_topic(11,50)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[11, 13, 19, 8, 18, 2, 16, 4, 14, 7, 15, 17, 1, 3, 9, 12, 10, 6, 5, 0]\n",
        "[u'the', u'and', u'is', u'are', u'food', u'great', u'good', u'they', u'very', u'service', u'always', u'their', u'staff', u'have', u'nice', u'for', u'really', u'happy', u'pretty', u'of', u'friendly', u'menu', u'all', u'but', u'quality', u'a', u'prices', u'clean', u'as', u'on', u'also', u'you', u'with', u'selection', u'here', u'so', u'hour', u'=)', u'drinks', u'nails', u'tasty', u'there', u'thank', u'helpful', u'run', u'mexican', u'etc', u'too', u'fresh', u'everything']\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}